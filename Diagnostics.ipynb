{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compatible-version",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "Run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorporate-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgb_test as xt\n",
    "import xgb_model as x\n",
    "import pandas as pd\n",
    "import pyinputplus as pyip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attended-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_run(**kwargs):\n",
    "    train, tourn = x.load_data()\n",
    "    feature_names = x.load_features(train)\n",
    "    train = x.feature_interactions_intel_dexte(train)\n",
    "    tourn = x.feature_interactions_intel_dexte(tourn)\n",
    "    feature_names = x.load_features(train)\n",
    "    feature_names_orig = feature_names[:310]\n",
    "    train, tourn, model = xt.test_model_xgb(train, tourn, feature_names, **kwargs)\n",
    "    return train, tourn, model, feature_names_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premium-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostics_all(train, tourn, feature_names_orig):\n",
    "    diagnostics0 = xt.diagnostics(train, tourn, feature_names_orig)\n",
    "    diagnostics0 = {f'0_neut_{k}': v for k, v in diagnostics0.items()}\n",
    "    \n",
    "    train50 = x.neut_by_era(train, feature_names_orig, .5)\n",
    "    tourn50 = x.neut_by_era(tourn, feature_names_orig, .5)\n",
    "    diagnostics50 = xt.diagnostics(train50, tourn50, feature_names_orig)\n",
    "    diagnostics50 = {f'0.5_neut_{k}': v for k, v in diagnostics50.items()}\n",
    "    \n",
    "    train100 = x.neut_by_era(train, feature_names_orig, 1)\n",
    "    tourn100 = x.neut_by_era(tourn, feature_names_orig, 1)\n",
    "    diagnostics100 = xt.diagnostics(train100, tourn100, feature_names_orig)\n",
    "    diagnostics100 = {f'1_neut_{k}': v for k, v in diagnostics100.items()}\n",
    "    \n",
    "    # concat dicts\n",
    "    diag = {**diagnostics0, **diagnostics50, **diagnostics100}\n",
    "    diag_df = pd.DataFrame([diag])\n",
    "    return diag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exotic-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_params_diagnostics(model, diag_df):\n",
    "    model_params_df = pd.DataFrame([model.get_params()])\n",
    "    params_diagnostics = pd.concat([model_params_df, diag_df], axis=1)\n",
    "    return params_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moral-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_cv_scores(params_diagnostics):    \n",
    "    try:\n",
    "        df = pd.read_csv('params_diagnostics.csv', index_col=0)\n",
    "    except:\n",
    "        print(f'{x.get_time()} No file named params_diagnostics.csv')\n",
    "        return params_diagnostics\n",
    "    else:\n",
    "        combined = pd.concat([df, params_diagnostics], axis=0).reset_index(drop=True)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "industrial-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_cv_scores(combined):\n",
    "    choice = pyip.inputChoice(['y', 'n'], prompt='Export to params_diagnostics.csv? y/n...')\n",
    "    if choice == 'y' or choice == 'Y':\n",
    "        print(f'{x.get_time()} Exporting...', end='', flush=True)\n",
    "        combined.to_csv('params_diagnostics.csv')\n",
    "        print(f'{x.get_time()} Done.')\n",
    "    else:\n",
    "        print(f'{x.get_time()} Not exporting.')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-opera",
   "metadata": {},
   "source": [
    "## Run diagnostics\n",
    "1. Include model parameters in the arguments for `load_and_run()`.\n",
    "1. Run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sacred-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:52:19 Loading data from round 263...08:53:03 Done.\n",
      "08:53:03 Loaded 310 features.\n",
      "08:53:03 Adding 2nd order interactions between intelligence and dexterity features...08:53:07 Done.\n",
      "08:53:07 Adding 2nd order interactions between intelligence and dexterity features...08:53:20 Done.\n",
      "08:53:20 Loaded 661 features.\n",
      "08:53:20 Training model...\n",
      "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=0.07, gamma=None,\n",
      "             gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.003, max_delta_step=None, max_depth=5,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=4000, n_jobs=None, num_parallel_tree=None,\n",
      "             random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=0.75, tree_method='gpu_hist',\n",
      "             validate_parameters=None, verbosity=None)\n",
      "08:58:42 Done.\n",
      "08:58:42 Generating predictions...08:59:22 Done.\n"
     ]
    }
   ],
   "source": [
    "train, tourn, model, feature_names_orig = load_and_run(n_estimators=4000, colsample_bytree=0.07, learning_rate=0.003, max_depth=5, subsample=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "timely-banana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:59:22 Calculating diagnostics...08:59:43 Done.\n",
      "08:59:43 Neutralizing 50.0% by era...09:00:06 Done.\n",
      "09:00:06 Neutralizing 50.0% by era...09:01:24 Done.\n",
      "09:01:24 Calculating diagnostics...09:01:45 Done.\n",
      "09:01:45 Neutralizing 100% by era...09:02:07 Done.\n",
      "09:02:07 Neutralizing 100% by era...09:03:20 Done.\n",
      "09:03:20 Calculating diagnostics...09:03:43 Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objective</th>\n",
       "      <th>base_score</th>\n",
       "      <th>booster</th>\n",
       "      <th>colsample_bylevel</th>\n",
       "      <th>colsample_bynode</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>gpu_id</th>\n",
       "      <th>importance_type</th>\n",
       "      <th>interaction_constraints</th>\n",
       "      <th>...</th>\n",
       "      <th>1_neut_validation_corr_std</th>\n",
       "      <th>1_neut_validation_sharpe</th>\n",
       "      <th>1_neut_max_drawdown</th>\n",
       "      <th>1_neut_max_feature_exposure</th>\n",
       "      <th>1_neut_feature_neutral_mean</th>\n",
       "      <th>1_neut_validation_mmc_mean</th>\n",
       "      <th>1_neut_validation_mmc_sharpe</th>\n",
       "      <th>1_neut_corr_plus_mmc_mean</th>\n",
       "      <th>1_neut_corr_plus_mmc_sharpe</th>\n",
       "      <th>1_neut_corr_with_example_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>0.5</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gain</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0.01493</td>\n",
       "      <td>1.404405</td>\n",
       "      <td>-0.025133</td>\n",
       "      <td>0.01591</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.45997</td>\n",
       "      <td>0.02665</td>\n",
       "      <td>1.090948</td>\n",
       "      <td>0.507508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          objective  base_score booster  colsample_bylevel  colsample_bynode  \\\n",
       "0  reg:squarederror         0.5  gbtree                  1                 1   \n",
       "\n",
       "   colsample_bytree  gamma  gpu_id importance_type interaction_constraints  \\\n",
       "0              0.07      0       0            gain                           \n",
       "\n",
       "   ...  1_neut_validation_corr_std  1_neut_validation_sharpe  \\\n",
       "0  ...                     0.01493                  1.404405   \n",
       "\n",
       "   1_neut_max_drawdown  1_neut_max_feature_exposure  \\\n",
       "0            -0.025133                      0.01591   \n",
       "\n",
       "   1_neut_feature_neutral_mean 1_neut_validation_mmc_mean  \\\n",
       "0                     0.017351                   0.005682   \n",
       "\n",
       "   1_neut_validation_mmc_sharpe  1_neut_corr_plus_mmc_mean  \\\n",
       "0                       0.45997                    0.02665   \n",
       "\n",
       "   1_neut_corr_plus_mmc_sharpe  1_neut_corr_with_example_preds  \n",
       "0                     1.090948                        0.507508  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_df = diagnostics_all(train, tourn, feature_names_orig)\n",
    "params_diagnostics = combine_params_diagnostics(model, diag_df)\n",
    "params_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "terminal-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export to params_diagnostics.csv? y/n...y\n",
      "09:04:44 Exporting...09:04:44 Done.\n"
     ]
    }
   ],
   "source": [
    "combined = append_cv_scores(params_diagnostics)\n",
    "export_cv_scores(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-advice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
